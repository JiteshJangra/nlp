{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797d06d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "\n",
       "                             Director Cast    Genre  \\\n",
       "0                             Unknown  NaN  unknown   \n",
       "1                             Unknown  NaN  unknown   \n",
       "2                             Unknown  NaN  unknown   \n",
       "3                             Unknown  NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Read data. \n",
    "movies_raw_df = pd.read_csv('wiki_movie_plots_deduped.csv')\n",
    "\n",
    "movies_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff7caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_to_select = ((movies_raw_df['Genre'] == 'horror') &\n",
    "                    # Restrict to American movies. \n",
    "                    (movies_raw_df['Origin/Ethnicity'] == 'American') &\n",
    "                    # Only movies from 2000.\n",
    "                    (movies_raw_df['Release Year'] > 1999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519618ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13617    In November 1999, tourists and fans of The Bla...\n",
       "13640    Matthew Van Helsing, the alleged descendant of...\n",
       "13681    A small group of fervent Roman Catholics belie...\n",
       "13731    Cotton Weary, now living in Los Angeles and th...\n",
       "13763    Amy Mayfield, a student at a prestigious film ...\n",
       "Name: Plot, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horror_df = movies_raw_df[movies_to_select]['Plot']\n",
    "\n",
    "horror_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c2a606d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horror_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22644f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all plots into a string.\n",
    "horror_str = horror_df.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f73b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load language model. \n",
    "nlp = spacy.load('en', disable = ['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371ccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(doc_text):\n",
    "    # This pattern is a modification of the defaul filter from the\n",
    "    # Tokenizer() object in keras.preprocessing.text. \n",
    "    # It just indicates which patters no skip.\n",
    "    skip_pattern = '\\r\\n \\n\\n \\n\\n\\n!\"-#$%&()--.*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r '\n",
    "    \n",
    "    tokens = [token.text.lower() for token in nlp(doc_text) if token.text not in skip_pattern]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe56b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'november', '1999', 'tourists', 'and', 'fans', 'of', 'the', 'blair']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tokens.\n",
    "tokens = get_tokens(horror_str)\n",
    "# Let us see the first tokens.\n",
    "tokens[0:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cf54b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165871"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the number of tokens list.\n",
    "len(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dbb31ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'november',\n",
       " '1999',\n",
       " 'tourists',\n",
       " 'and',\n",
       " 'fans',\n",
       " 'of',\n",
       " 'the',\n",
       " 'blair',\n",
       " 'witch',\n",
       " 'project',\n",
       " 'descend',\n",
       " 'on',\n",
       " 'the',\n",
       " 'small',\n",
       " 'town',\n",
       " 'of',\n",
       " 'burkittsville',\n",
       " 'maryland',\n",
       " 'where',\n",
       " 'the',\n",
       " 'film',\n",
       " 'is',\n",
       " 'set',\n",
       " 'local']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_0 = 25\n",
    "\n",
    "tokens[0:len_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c748a1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resident']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[len_0:len_0 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ec9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len_0 + 1\n",
    "\n",
    "text_sequences = []\n",
    "for i in range(train_len, len(tokens)):\n",
    "    # Construct sequence.\n",
    "    seq = tokens[i - train_len: i]\n",
    "    # Append.\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cf84bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in november 1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ec00c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdfb10cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in november 1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident\n",
      "-----\n",
      "november 1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff\n",
      "-----\n",
      "1999 tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff a\n",
      "-----\n",
      "tourists and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff a former\n",
      "-----\n",
      "and fans of the blair witch project descend on the small town of burkittsville maryland where the film is set local resident jeff a former psychiatric\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print(' '.join(text_sequences[i]))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e5bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#for gpu in gpus:\n",
    "  #tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "062f4ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f6748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric sequences.\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba36945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 12586,\n",
       " 12585,\n",
       " 2397,\n",
       " 2,\n",
       " 12584,\n",
       " 5,\n",
       " 1,\n",
       " 5558,\n",
       " 630,\n",
       " 2195,\n",
       " 2927,\n",
       " 20,\n",
       " 1,\n",
       " 450,\n",
       " 157,\n",
       " 5,\n",
       " 12583,\n",
       " 7487,\n",
       " 42,\n",
       " 1,\n",
       " 117,\n",
       " 7,\n",
       " 362,\n",
       " 231,\n",
       " 2928]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bb050e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1da4cab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12586"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0750e95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    8, 12586, 12585, ...,   362,   231,  2928],\n",
       "       [12586, 12585,  2397, ...,   231,  2928,   297],\n",
       "       [12585,  2397,     2, ...,  2928,   297,     4],\n",
       "       ...,\n",
       "       [   20,     4,  1551, ...,     1,    59,     5],\n",
       "       [    4,  1551,  1684, ...,    59,     5,     6],\n",
       "       [ 1551,  1684,    22, ...,     5,     6,   169]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We store the sequences in a numpy array.\n",
    "sequences = np.array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb93b371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    8, 12586, 12585, ...,     7,   362,   231],\n",
       "       [12586, 12585,  2397, ...,   362,   231,  2928],\n",
       "       [12585,  2397,     2, ...,   231,  2928,   297],\n",
       "       ...,\n",
       "       [   20,     4,  1551, ...,    22,     1,    59],\n",
       "       [    4,  1551,  1684, ...,     1,    59,     5],\n",
       "       [ 1551,  1684,    22, ...,    59,     5,     6]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# select all but last word indices.\n",
    "X = sequences[:, :-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c95e8312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165845, 25)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e702b972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2928,  297,    4, ...,    5,    6,  169])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = X.shape[1]\n",
    "# select all last word indices.\n",
    "y = sequences[:, -1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3caa58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to categorical (we add + 1 because Keras needs a placeholder).\n",
    "y = to_categorical(y, num_classes=(vocabulary_size + 1))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f16fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 25, 25)            314675    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 25, 50)            15200     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12587)             641937    \n",
      "=================================================================\n",
      "Total params: 994,562\n",
      "Trainable params: 994,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "def create_model(vocabulary_size, seq_len):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim=vocabulary_size, \n",
    "                        output_dim=seq_len, \n",
    "                        input_length=seq_len))\n",
    "    \n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    \n",
    "    model.add(LSTM(units=50))\n",
    "    \n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(units=vocabulary_size, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "# Let us create the model and see summary.\n",
    "model = create_model(vocabulary_size=(vocabulary_size + 1), seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f4d6340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 5.1027 - accuracy: 0.1618\n",
      "Epoch 2/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 5.0541 - accuracy: 0.1635\n",
      "Epoch 3/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 5.0099 - accuracy: 0.1658\n",
      "Epoch 4/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.9645 - accuracy: 0.1673\n",
      "Epoch 5/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.9211 - accuracy: 0.1696\n",
      "Epoch 6/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.8780 - accuracy: 0.1714\n",
      "Epoch 7/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.8382 - accuracy: 0.1735\n",
      "Epoch 8/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.7994 - accuracy: 0.1754\n",
      "Epoch 9/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.7617 - accuracy: 0.1771\n",
      "Epoch 10/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.7257 - accuracy: 0.1788\n",
      "Epoch 11/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.6911 - accuracy: 0.1808\n",
      "Epoch 12/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.6577 - accuracy: 0.1828\n",
      "Epoch 13/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.6264 - accuracy: 0.1848\n",
      "Epoch 14/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.5950 - accuracy: 0.1870\n",
      "Epoch 15/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.5652 - accuracy: 0.1896\n",
      "Epoch 16/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.5363 - accuracy: 0.1911\n",
      "Epoch 17/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.5071 - accuracy: 0.1935\n",
      "Epoch 18/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.4792 - accuracy: 0.1951\n",
      "Epoch 19/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.4516 - accuracy: 0.1981\n",
      "Epoch 20/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.4245 - accuracy: 0.1997\n",
      "Epoch 21/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.3976 - accuracy: 0.2021\n",
      "Epoch 22/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.3703 - accuracy: 0.2051\n",
      "Epoch 23/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.3442 - accuracy: 0.2073\n",
      "Epoch 24/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.3209 - accuracy: 0.2093\n",
      "Epoch 25/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.2944 - accuracy: 0.2114\n",
      "Epoch 26/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.2701 - accuracy: 0.2134\n",
      "Epoch 27/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.2462 - accuracy: 0.2156\n",
      "Epoch 28/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.2234 - accuracy: 0.2180\n",
      "Epoch 29/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.2024 - accuracy: 0.2199\n",
      "Epoch 30/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 4.1792 - accuracy: 0.2223\n",
      "Epoch 31/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.1603 - accuracy: 0.2235\n",
      "Epoch 32/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.1367 - accuracy: 0.2260\n",
      "Epoch 33/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.1197 - accuracy: 0.2276\n",
      "Epoch 34/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 4.0976 - accuracy: 0.2296\n",
      "Epoch 35/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 4.0794 - accuracy: 0.2315\n",
      "Epoch 36/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.0613 - accuracy: 0.2341\n",
      "Epoch 37/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.0441 - accuracy: 0.2366\n",
      "Epoch 38/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 4.0267 - accuracy: 0.2377\n",
      "Epoch 39/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 4.0095 - accuracy: 0.2397\n",
      "Epoch 40/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.9924 - accuracy: 0.2416\n",
      "Epoch 41/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.9756 - accuracy: 0.2430\n",
      "Epoch 42/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.9616 - accuracy: 0.2445\n",
      "Epoch 43/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.9456 - accuracy: 0.2456\n",
      "Epoch 44/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.9299 - accuracy: 0.2488\n",
      "Epoch 45/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.9153 - accuracy: 0.2503\n",
      "Epoch 46/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.9011 - accuracy: 0.2525\n",
      "Epoch 47/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.8872 - accuracy: 0.2529\n",
      "Epoch 48/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.8726 - accuracy: 0.2548\n",
      "Epoch 49/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.8608 - accuracy: 0.2558\n",
      "Epoch 50/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.8437 - accuracy: 0.2582\n",
      "Epoch 51/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.8350 - accuracy: 0.2593\n",
      "Epoch 52/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.8226 - accuracy: 0.2608\n",
      "Epoch 53/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.8080 - accuracy: 0.2632\n",
      "Epoch 54/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.7937 - accuracy: 0.2644\n",
      "Epoch 55/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.7837 - accuracy: 0.2657\n",
      "Epoch 56/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.7709 - accuracy: 0.2659\n",
      "Epoch 57/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 3.7646 - accuracy: 0.2684\n",
      "Epoch 58/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.7488 - accuracy: 0.2700\n",
      "Epoch 59/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.7336 - accuracy: 0.2705\n",
      "Epoch 60/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 3.7228 - accuracy: 0.2726\n",
      "Epoch 61/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 3.7119 - accuracy: 0.2738\n",
      "Epoch 62/100\n",
      "1296/1296 [==============================] - 21s 16ms/step - loss: 3.6994 - accuracy: 0.2747\n",
      "Epoch 63/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.6890 - accuracy: 0.2772\n",
      "Epoch 64/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.6772 - accuracy: 0.2783\n",
      "Epoch 65/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.6649 - accuracy: 0.2805\n",
      "Epoch 66/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.6545 - accuracy: 0.2801\n",
      "Epoch 67/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.6390 - accuracy: 0.2820\n",
      "Epoch 68/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.6294 - accuracy: 0.2841\n",
      "Epoch 69/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.6128 - accuracy: 0.2863\n",
      "Epoch 70/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.6020 - accuracy: 0.2864\n",
      "Epoch 71/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.5956 - accuracy: 0.2871\n",
      "Epoch 72/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.5792 - accuracy: 0.2893\n",
      "Epoch 73/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.5620 - accuracy: 0.2910\n",
      "Epoch 74/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.5505 - accuracy: 0.2927\n",
      "Epoch 75/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.5394 - accuracy: 0.2943\n",
      "Epoch 76/100\n",
      "1296/1296 [==============================] - 21s 16ms/step - loss: 3.5283 - accuracy: 0.2960\n",
      "Epoch 77/100\n",
      "1296/1296 [==============================] - 20s 16ms/step - loss: 3.5164 - accuracy: 0.2977\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.5031 - accuracy: 0.2983\n",
      "Epoch 79/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.4949 - accuracy: 0.3002\n",
      "Epoch 80/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.4836 - accuracy: 0.3016\n",
      "Epoch 81/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.4721 - accuracy: 0.3028\n",
      "Epoch 82/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.4582 - accuracy: 0.3048\n",
      "Epoch 83/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.4514 - accuracy: 0.3063\n",
      "Epoch 84/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.4352 - accuracy: 0.3080\n",
      "Epoch 85/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.4272 - accuracy: 0.3090\n",
      "Epoch 86/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.4210 - accuracy: 0.3097\n",
      "Epoch 87/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.4072 - accuracy: 0.3116\n",
      "Epoch 88/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.3963 - accuracy: 0.3133\n",
      "Epoch 89/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.3876 - accuracy: 0.3144\n",
      "Epoch 90/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.3760 - accuracy: 0.3155\n",
      "Epoch 91/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.3680 - accuracy: 0.3161\n",
      "Epoch 92/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.3586 - accuracy: 0.3192\n",
      "Epoch 93/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.3507 - accuracy: 0.3199\n",
      "Epoch 94/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.3399 - accuracy: 0.3211\n",
      "Epoch 95/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.3335 - accuracy: 0.3221\n",
      "Epoch 96/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.3229 - accuracy: 0.3226\n",
      "Epoch 97/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.3156 - accuracy: 0.3245\n",
      "Epoch 98/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.3086 - accuracy: 0.3246\n",
      "Epoch 99/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.3041 - accuracy: 0.3258\n",
      "Epoch 100/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.2894 - accuracy: 0.3276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26d01ad35e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, batch_size=128, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7a0e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5183/5183 [==============================] - 34s 7ms/step - loss: 3.1822 - accuracy: 0.3449\n",
      "Loss: 3.182206392288208\n",
      "Accuracy: 0.34490036964416504\n"
     ]
    }
   ],
   "source": [
    "# Get model metrics.\n",
    "loss, accuracy =  model.evaluate(x=X, y=y)\n",
    "print(f'Loss: {loss}\\nAccuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3ac9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.2835 - accuracy: 0.3289\n",
      "Epoch 2/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2738 - accuracy: 0.3296\n",
      "Epoch 3/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2702 - accuracy: 0.3308\n",
      "Epoch 4/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2678 - accuracy: 0.3301\n",
      "Epoch 5/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2513 - accuracy: 0.3331\n",
      "Epoch 6/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.2457 - accuracy: 0.3345\n",
      "Epoch 7/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2385 - accuracy: 0.3344\n",
      "Epoch 8/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2286 - accuracy: 0.3364\n",
      "Epoch 9/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2241 - accuracy: 0.3370\n",
      "Epoch 10/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.2110 - accuracy: 0.3388\n",
      "Epoch 11/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.2035 - accuracy: 0.3402\n",
      "Epoch 12/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.1992 - accuracy: 0.3407\n",
      "Epoch 13/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.1916 - accuracy: 0.3408\n",
      "Epoch 14/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.1844 - accuracy: 0.3421\n",
      "Epoch 15/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.1735 - accuracy: 0.3444\n",
      "Epoch 16/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.1729 - accuracy: 0.3444\n",
      "Epoch 17/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 3.1628 - accuracy: 0.3451\n",
      "Epoch 18/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.1542 - accuracy: 0.3472\n",
      "Epoch 19/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.1501 - accuracy: 0.3478\n",
      "Epoch 20/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.1422 - accuracy: 0.3474\n",
      "Epoch 21/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.1340 - accuracy: 0.3488\n",
      "Epoch 22/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.1277 - accuracy: 0.3499\n",
      "Epoch 23/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.1217 - accuracy: 0.3515\n",
      "Epoch 24/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.1128 - accuracy: 0.3523\n",
      "Epoch 25/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.1052 - accuracy: 0.3539\n",
      "Epoch 26/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.1009 - accuracy: 0.3540\n",
      "Epoch 27/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0939 - accuracy: 0.3540\n",
      "Epoch 28/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.0876 - accuracy: 0.3564\n",
      "Epoch 29/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.0865 - accuracy: 0.3558\n",
      "Epoch 30/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0762 - accuracy: 0.3576\n",
      "Epoch 31/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0714 - accuracy: 0.3586\n",
      "Epoch 32/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0621 - accuracy: 0.3596\n",
      "Epoch 33/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0566 - accuracy: 0.3609\n",
      "Epoch 34/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.0564 - accuracy: 0.3603\n",
      "Epoch 35/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0456 - accuracy: 0.3625\n",
      "Epoch 36/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0389 - accuracy: 0.3638\n",
      "Epoch 37/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0361 - accuracy: 0.3621\n",
      "Epoch 38/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0267 - accuracy: 0.3653\n",
      "Epoch 39/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0170 - accuracy: 0.3668\n",
      "Epoch 40/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 3.0181 - accuracy: 0.3665\n",
      "Epoch 41/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 3.0107 - accuracy: 0.3676\n",
      "Epoch 42/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.0071 - accuracy: 0.3684\n",
      "Epoch 43/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 3.0022 - accuracy: 0.3685\n",
      "Epoch 44/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.9957 - accuracy: 0.3701\n",
      "Epoch 45/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9921 - accuracy: 0.3705\n",
      "Epoch 46/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9907 - accuracy: 0.3707\n",
      "Epoch 47/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9798 - accuracy: 0.3721\n",
      "Epoch 48/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9690 - accuracy: 0.3740\n",
      "Epoch 49/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9698 - accuracy: 0.3735\n",
      "Epoch 50/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9680 - accuracy: 0.3746\n",
      "Epoch 51/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.9591 - accuracy: 0.3744\n",
      "Epoch 52/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9514 - accuracy: 0.3758\n",
      "Epoch 53/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.9492 - accuracy: 0.3764\n",
      "Epoch 54/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.9512 - accuracy: 0.3768\n",
      "Epoch 55/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9436 - accuracy: 0.3777\n",
      "Epoch 56/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9371 - accuracy: 0.3789\n",
      "Epoch 57/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9293 - accuracy: 0.3801\n",
      "Epoch 58/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.9264 - accuracy: 0.3805\n",
      "Epoch 59/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.9277 - accuracy: 0.3802\n",
      "Epoch 60/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.9169 - accuracy: 0.3817\n",
      "Epoch 61/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9156 - accuracy: 0.3817\n",
      "Epoch 62/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.9094 - accuracy: 0.3829\n",
      "Epoch 63/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 2.9206 - accuracy: 0.3814\n",
      "Epoch 64/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 2.9188 - accuracy: 0.3804\n",
      "Epoch 65/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8941 - accuracy: 0.3861\n",
      "Epoch 66/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 2.8918 - accuracy: 0.3850\n",
      "Epoch 67/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8895 - accuracy: 0.3855\n",
      "Epoch 68/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 2.8829 - accuracy: 0.3869\n",
      "Epoch 69/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8821 - accuracy: 0.3868\n",
      "Epoch 70/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8766 - accuracy: 0.3884\n",
      "Epoch 71/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8743 - accuracy: 0.3887\n",
      "Epoch 72/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8713 - accuracy: 0.3882\n",
      "Epoch 73/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8684 - accuracy: 0.3899\n",
      "Epoch 74/100\n",
      "1296/1296 [==============================] - 18s 14ms/step - loss: 2.8655 - accuracy: 0.3896\n",
      "Epoch 75/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8566 - accuracy: 0.3909\n",
      "Epoch 76/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8538 - accuracy: 0.3912\n",
      "Epoch 77/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8503 - accuracy: 0.3916\n",
      "Epoch 78/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8467 - accuracy: 0.3933\n",
      "Epoch 79/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8379 - accuracy: 0.3941\n",
      "Epoch 80/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8434 - accuracy: 0.3931\n",
      "Epoch 81/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8345 - accuracy: 0.3941\n",
      "Epoch 82/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8318 - accuracy: 0.3945\n",
      "Epoch 83/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8311 - accuracy: 0.3950\n",
      "Epoch 84/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8267 - accuracy: 0.3962\n",
      "Epoch 85/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 2.8189 - accuracy: 0.3968\n",
      "Epoch 86/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8174 - accuracy: 0.3973\n",
      "Epoch 87/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8145 - accuracy: 0.3967\n",
      "Epoch 88/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8369 - accuracy: 0.3939\n",
      "Epoch 89/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8102 - accuracy: 0.3978\n",
      "Epoch 90/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.7995 - accuracy: 0.4004\n",
      "Epoch 91/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8041 - accuracy: 0.3983\n",
      "Epoch 92/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.8004 - accuracy: 0.3994\n",
      "Epoch 93/100\n",
      "1296/1296 [==============================] - 19s 14ms/step - loss: 2.8016 - accuracy: 0.3988\n",
      "Epoch 94/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.7893 - accuracy: 0.4008\n",
      "Epoch 95/100\n",
      "1296/1296 [==============================] - 20s 16ms/step - loss: 2.7862 - accuracy: 0.4016\n",
      "Epoch 96/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 2.7901 - accuracy: 0.4010\n",
      "Epoch 97/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 2.7840 - accuracy: 0.4028\n",
      "Epoch 98/100\n",
      "1296/1296 [==============================] - 20s 15ms/step - loss: 2.7878 - accuracy: 0.4013\n",
      "Epoch 99/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.7732 - accuracy: 0.4046\n",
      "Epoch 100/100\n",
      "1296/1296 [==============================] - 19s 15ms/step - loss: 2.7710 - accuracy: 0.4039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26d12eef310>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, batch_size=128, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model metrics.\n",
    "loss, accuracy =  model.evaluate(x=X, y=y)\n",
    "print(f'Loss: {loss}\\nAccuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fcb609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.6139 - accuracy: 0.4352\n",
      "Epoch 2/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5452 - accuracy: 0.4493\n",
      "Epoch 3/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5230 - accuracy: 0.4556\n",
      "Epoch 4/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5144 - accuracy: 0.4565\n",
      "Epoch 5/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5117 - accuracy: 0.4571\n",
      "Epoch 6/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5138 - accuracy: 0.4571\n",
      "Epoch 7/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5184 - accuracy: 0.4564\n",
      "Epoch 8/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5230 - accuracy: 0.4545\n",
      "Epoch 9/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5242 - accuracy: 0.4548\n",
      "Epoch 10/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5267 - accuracy: 0.4532\n",
      "Epoch 11/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5318 - accuracy: 0.4516\n",
      "Epoch 12/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5307 - accuracy: 0.4520\n",
      "Epoch 13/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.5292 - accuracy: 0.4529\n",
      "Epoch 14/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5282 - accuracy: 0.4527\n",
      "Epoch 15/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5275 - accuracy: 0.4530\n",
      "Epoch 16/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.5196 - accuracy: 0.4543\n",
      "Epoch 17/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5181 - accuracy: 0.4549\n",
      "Epoch 18/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5154 - accuracy: 0.4548\n",
      "Epoch 19/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5133 - accuracy: 0.4545\n",
      "Epoch 20/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5079 - accuracy: 0.4567\n",
      "Epoch 21/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.5023 - accuracy: 0.4573\n",
      "Epoch 22/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.5017 - accuracy: 0.4579\n",
      "Epoch 23/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4974 - accuracy: 0.4586\n",
      "Epoch 24/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4976 - accuracy: 0.4588\n",
      "Epoch 25/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4927 - accuracy: 0.4595\n",
      "Epoch 26/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4884 - accuracy: 0.4598\n",
      "Epoch 27/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4885 - accuracy: 0.4606\n",
      "Epoch 28/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4898 - accuracy: 0.4595\n",
      "Epoch 29/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4828 - accuracy: 0.4609\n",
      "Epoch 30/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4786 - accuracy: 0.4616\n",
      "Epoch 31/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.4841 - accuracy: 0.4605\n",
      "Epoch 32/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4785 - accuracy: 0.4612\n",
      "Epoch 33/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.4716 - accuracy: 0.4627\n",
      "Epoch 34/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.4680 - accuracy: 0.4633\n",
      "Epoch 35/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.4627 - accuracy: 0.4644\n",
      "Epoch 36/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4613 - accuracy: 0.4658\n",
      "Epoch 37/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4595 - accuracy: 0.4642\n",
      "Epoch 38/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4605 - accuracy: 0.4640\n",
      "Epoch 39/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.4588 - accuracy: 0.4648\n",
      "Epoch 40/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4575 - accuracy: 0.4653\n",
      "Epoch 41/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4584 - accuracy: 0.4648\n",
      "Epoch 42/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4507 - accuracy: 0.4659\n",
      "Epoch 43/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4496 - accuracy: 0.4665\n",
      "Epoch 44/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4436 - accuracy: 0.4678\n",
      "Epoch 45/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4408 - accuracy: 0.4688\n",
      "Epoch 46/100\n",
      "324/324 [==============================] - 11s 34ms/step - loss: 2.4430 - accuracy: 0.4676\n",
      "Epoch 47/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4400 - accuracy: 0.4684\n",
      "Epoch 48/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4347 - accuracy: 0.4687\n",
      "Epoch 49/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4296 - accuracy: 0.4700\n",
      "Epoch 50/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4334 - accuracy: 0.4690\n",
      "Epoch 51/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.4350 - accuracy: 0.4697\n",
      "Epoch 52/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4338 - accuracy: 0.4698\n",
      "Epoch 53/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4307 - accuracy: 0.4693\n",
      "Epoch 54/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4214 - accuracy: 0.4715\n",
      "Epoch 55/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4185 - accuracy: 0.4728\n",
      "Epoch 56/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4181 - accuracy: 0.4725\n",
      "Epoch 57/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4288 - accuracy: 0.4693\n",
      "Epoch 58/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4160 - accuracy: 0.4724\n",
      "Epoch 59/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4095 - accuracy: 0.4737\n",
      "Epoch 60/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4121 - accuracy: 0.4731\n",
      "Epoch 61/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4150 - accuracy: 0.4728\n",
      "Epoch 62/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4083 - accuracy: 0.4734\n",
      "Epoch 63/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4082 - accuracy: 0.4741\n",
      "Epoch 64/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.4041 - accuracy: 0.4749\n",
      "Epoch 65/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.4018 - accuracy: 0.4748\n",
      "Epoch 66/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.3984 - accuracy: 0.4762\n",
      "Epoch 67/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3951 - accuracy: 0.4765\n",
      "Epoch 68/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.3967 - accuracy: 0.4753\n",
      "Epoch 69/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.3993 - accuracy: 0.4749\n",
      "Epoch 70/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.3927 - accuracy: 0.4763\n",
      "Epoch 71/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.3893 - accuracy: 0.4775\n",
      "Epoch 72/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.3930 - accuracy: 0.4762\n",
      "Epoch 73/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3882 - accuracy: 0.4774\n",
      "Epoch 74/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3885 - accuracy: 0.4775\n",
      "Epoch 75/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3883 - accuracy: 0.4767\n",
      "Epoch 76/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3826 - accuracy: 0.4784\n",
      "Epoch 77/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3800 - accuracy: 0.4782\n",
      "Epoch 78/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.3758 - accuracy: 0.4796\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3896 - accuracy: 0.4769\n",
      "Epoch 80/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3832 - accuracy: 0.4776\n",
      "Epoch 81/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3759 - accuracy: 0.4794\n",
      "Epoch 82/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3695 - accuracy: 0.4818\n",
      "Epoch 83/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3674 - accuracy: 0.4819\n",
      "Epoch 84/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3656 - accuracy: 0.4811\n",
      "Epoch 85/100\n",
      "324/324 [==============================] - 11s 34ms/step - loss: 2.3635 - accuracy: 0.4819\n",
      "Epoch 86/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3671 - accuracy: 0.4807\n",
      "Epoch 87/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3617 - accuracy: 0.4814\n",
      "Epoch 88/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3612 - accuracy: 0.4817\n",
      "Epoch 89/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3626 - accuracy: 0.4813\n",
      "Epoch 90/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3620 - accuracy: 0.4813\n",
      "Epoch 91/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3615 - accuracy: 0.4824\n",
      "Epoch 92/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3603 - accuracy: 0.4830\n",
      "Epoch 93/100\n",
      "324/324 [==============================] - 10s 32ms/step - loss: 2.3489 - accuracy: 0.4839\n",
      "Epoch 94/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3496 - accuracy: 0.4838\n",
      "Epoch 95/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3452 - accuracy: 0.4846\n",
      "Epoch 96/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.3490 - accuracy: 0.4838\n",
      "Epoch 97/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3527 - accuracy: 0.4836\n",
      "Epoch 98/100\n",
      "324/324 [==============================] - 11s 33ms/step - loss: 2.3518 - accuracy: 0.4829\n",
      "Epoch 99/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.3487 - accuracy: 0.4831\n",
      "Epoch 100/100\n",
      "324/324 [==============================] - 11s 32ms/step - loss: 2.3473 - accuracy: 0.4836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26d12f0d580>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, batch_size=512, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e011d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afbc06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5183/5183 [==============================] - 34s 6ms/step - loss: 2.2862 - accuracy: 0.4981\n",
      "Loss: 2.2861976623535156\n",
      "Accuracy: 0.4980553984642029\n"
     ]
    }
   ],
   "source": [
    "# Get model metrics.\n",
    "loss, accuracy =  model.evaluate(x=X, y=y)\n",
    "print(f'Loss: {loss}\\nAccuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e16a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c20b0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "dump(tokenizer, open('tokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a44a43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5daf959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "501894d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    # List to store the generated words. \n",
    "    output_text = []\n",
    "    # Set seed_text as input_text. \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        # Encode input text. \n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        # Add if the input tesxt does not have length len_0.\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        # Do the prediction. Here we automatically choose the word with highest probability. \n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        # Convert from numeric to word. \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        # Attach predicted word. \n",
    "        input_text += ' ' + pred_word\n",
    "        # Append new word to the list. \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0aa07ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Officer Frank Williams (Steven Vidler) and his partner Blaine investigate an abandoned house, where they find a young woman with her eyes ripped out. A large figure with an axe then murders Blaine and Frank has his arm chopped off before he is able to shoot the attacker in the head. Afterwards, detectives find seven bodies in the house, all of which have had their eyes ripped out.\n"
     ]
    }
   ],
   "source": [
    "sample_text = horror_df.iloc[100][:383]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1b4bf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Officer Frank Williams (Steven Vidler) and his partner Blaine investigate an abandoned house, where they find a young woman with her eyes ripped out. A large figure with an axe then murders \n"
     ]
    }
   ],
   "source": [
    "seed_text = sample_text[:190]\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f830a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jitesh\\AppData\\Local\\Temp\\ipykernel_9480\\1038174353.py:15: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Officer Frank Williams (Steven Vidler) and his partner Blaine investigate an abandoned house, where they find a young woman with her eyes ripped out. A large figure with an axe then murders  blaine and the remote founding fathers lying to retrieve her preston spins out the citizens abruptly hudson is arrested for henry hewitt a hound of iran she travels to the conclusion that she is not the same treatment mad tells...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model=model, \n",
    "                               tokenizer=tokenizer,\n",
    "                               seq_len=seq_len, \n",
    "                               seed_text=seed_text, \n",
    "                               num_gen_words=40)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bca632f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = 'the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44ae7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear the parasite but quentin is rendered distraught from the hospital and finds a bottle of report a few years later the rest of the group are then a dream of the mirror prompting him about screen deucalion is sitting somewhere ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ......\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model=model, \n",
    "                               tokenizer=tokenizer,\n",
    "                               seq_len=seq_len, \n",
    "                               seed_text=seed_text, \n",
    "                               num_gen_words=80)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdf48db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cocky college football star Francis Finnegan has his eye on the attractive Gloria van Dayham, as does his rival, Larry Stacey.\r\n",
      "Francis gets a job in a department store owned by Stacey's father, where salesgirl June Cort develops an attraction to him. Finnegan proposes that Stacey's store sponsor a football team, which causes rival shop owner Whimple to do likewise. The team's head cheerleader, Mimi, falls for team mascot Joe, meanwhile, and everybody pairs off with the perfect partner after the big game.\n"
     ]
    }
   ],
   "source": [
    "seed_text = movies_raw_df[movies_raw_df['Genre'] == 'comedy']['Plot'].iloc[330]\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9931eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text2(model, tokenizer, seq_len, seed_text, num_gen_words, temperature):\n",
    "    \n",
    "    output_text = []\n",
    "    \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        # Encode input text. \n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "         # Add if the input tesxt does not have length len_0.\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        # Get learned distribution.\n",
    "        pred_distribution = model.predict(pad_encoded, verbose=0)[0]\n",
    "        \n",
    "        # Apply temperature transformation.\n",
    "        new_pred_distribution = np.power(pred_distribution, (1 / temperature)) \n",
    "        new_pred_distribution = new_pred_distribution / new_pred_distribution.sum()\n",
    "        \n",
    "        # Sample from modified distribution.\n",
    "        choices = range(new_pred_distribution.size)\n",
    " \n",
    "        pred_word_ind = np.random.choice(a=choices, p=new_pred_distribution)\n",
    "        \n",
    "        # Convert from numeric to word. \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        # Attach predicted word. \n",
    "        input_text += ' ' + pred_word\n",
    "        # Append new word to the list. \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50246bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = 'the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc7e76d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear the parasite in the process ultimately then 've ca house explosion or enter the basement in jennifer 's involvement doris is dramatic fictions hybrid chokes ambushes the car ringing the spirit 's eventually friend zoe confronts laurel being finally a dream as screen bathory has been dreams that it is herself wrong they are in the sanctuary with entering sonja timmy eva notices a woman named logan taylor and abigail embrace to the family on the future at his house ...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text2(model=model, \n",
    "                                tokenizer=tokenizer,\n",
    "                                seq_len=seq_len, \n",
    "                                seed_text=seed_text, \n",
    "                                num_gen_words=80, \n",
    "                                temperature=0.9)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + ' ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63c823a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear the parasite but quentin and scott popular chase the cops eden making to rather by smiles and throws her off to blister they search and slaughter by letch where if g.m. g.m. g.m. g.m. has unknowingly revealed to sound an advantage to pursue the vatican and stabs her in the head and to find her and uses it who does n't edward brodus jeff to lift it out of the tub and are unable to evacuate them and the cannibals  other ...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text2(model=model, \n",
    "                                tokenizer=tokenizer,\n",
    "                                seq_len=seq_len, \n",
    "                                seed_text=seed_text, \n",
    "                                num_gen_words=82, \n",
    "                                temperature=0.5)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + ' ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5214b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film starts in a dark house where a group of teenagers friends meet to spend the weekend when they suddenly hear the parasite but quentin is rendered catatonic and murders the next scene katie confesses that he is suicidal and is violently treated the zombies but captain roman andrews twenty lamia the cage 's exit dying and snaps at the beach she is a psychopath necrophile and serial rapist he holds the creature in the basement where she finds that the rollins family the next day andrews promises to fix the containers which is knocked on the gun and kills her with the ...\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text2(model=model, \n",
    "                                tokenizer=tokenizer,\n",
    "                                seq_len=seq_len, \n",
    "                                seed_text=seed_text, \n",
    "                                num_gen_words=82, \n",
    "                                temperature = 0.1)\n",
    "\n",
    "print(seed_text + ' ' + generated_text + ' ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4529603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e524a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
